{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitvenvvenv47b65cf57d4d48c1aee271492c637f7a",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['../config.ini']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import praw\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=config['default']['client_id'],\n",
    "client_secret=config['default']['client_secret'],\n",
    "password = config['default']['password'],\n",
    " user_agent=config['default']['user_agent'],\n",
    " username = config['default']['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "automatic-benji\n"
    }
   ],
   "source": [
    "# print(reddit.auth.authorize(code))\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(subname,limit_val=10):\n",
    "    print(f'~Getting posts for {subname} with limit {limit_val}')\n",
    "    posts = []\n",
    "    ml_subreddit = reddit.subreddit(subname)\n",
    "    for post in ml_subreddit.hot(limit=limit_val):\n",
    "        posts.append([post.id, \n",
    "        post.title,\n",
    "        post.created_utc,\n",
    "        post.score, \n",
    "        post.subreddit, \n",
    "        post.url, \n",
    "        post.num_comments, \n",
    "        post.selftext,\n",
    "        post.stickied,\n",
    "        post.spoiler,\n",
    "        post.subreddit_subscribers,\n",
    "        post.subreddit_type,\n",
    "        post.subreddit_id,\n",
    "        post.subreddit,\n",
    "        post.total_awards_received,\n",
    "        post.ups,\n",
    "        post.downs,\n",
    "        post.upvote_ratio,\n",
    "        post.view_count,\n",
    "        post.quarantine,\n",
    "        post.removal_reason,\n",
    "        post.removed_by_category,\n",
    "        post.report_reasons,\n",
    "        post.pinned,\n",
    "        post.permalink,\n",
    "        post.over_18,\n",
    "        post.num_reports,\n",
    "        post.num_duplicates,\n",
    "        post.num_crossposts,\n",
    "        post.num_comments,\n",
    "        post.no_follow,\n",
    "        post.media,\n",
    "        post.media_embed,\n",
    "        post.media_only,\n",
    "        post.is_video,\n",
    "        post.is_original_content,\n",
    "        post.gilded,\n",
    "        post.edited,\n",
    "        post.category,\n",
    "        post.banned_at_utc,\n",
    "        post.archived])\n",
    "\n",
    "    postsDF = pd.DataFrame(posts,columns=['id', \n",
    "        'title',\n",
    "        'created_utc',\n",
    "        'score', \n",
    "        'subreddit', \n",
    "        'url', \n",
    "        'num_comments', \n",
    "        'selftext',\n",
    "        'stickied',\n",
    "        'spoiler',\n",
    "        'subreddit_subscribers',\n",
    "        'subreddit_type',\n",
    "        'subreddit_id',\n",
    "        'subreddit',\n",
    "        'total_awards_received',\n",
    "        'ups',\n",
    "        'downs',\n",
    "        'upvote_ratio',\n",
    "        'view_count',\n",
    "        'quarantine',\n",
    "        'removal_reason',\n",
    "        'removed_by_category',\n",
    "        'report_reasons',\n",
    "        'pinned',\n",
    "        'permalink',\n",
    "        'over_18',\n",
    "        'num_reports',\n",
    "        'num_duplicates',\n",
    "        'num_crossposts',\n",
    "        'num_comments',\n",
    "        'no_follow',\n",
    "        'media',\n",
    "        'media_embed',\n",
    "        'media_only',\n",
    "        'is_video',\n",
    "        'is_original_content',\n",
    "        'gilded',\n",
    "        'edited',\n",
    "        'category',\n",
    "        'banned_at_utc',\n",
    "        'archived'])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#convert dates to date time\n",
    "    postsDF['created_utc'] = pd.to_datetime(postsDF['created_utc'] , format=None,unit='s',origin='unix')\n",
    "    postsDF['banned_at_utc'] = pd.to_datetime(postsDF['banned_at_utc'] , format=None,unit='s',origin='unix')\n",
    "\n",
    "\n",
    "    print(f'~Done!!! {postsDF.shape[0]} posts found in {subname}')\n",
    "\n",
    "    return postsDF\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# import pprint\n",
    "\n",
    "# # assume you have a Reddit instance bound to variable `reddit`\n",
    "# submission = reddit.submission(url = posts['url'][0])\n",
    "# print(submission.title) # to make it non-lazy\n",
    "# pprint.pprint(vars(submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_comments(url):\n",
    "    print(f'~Getting comments for: {url}')\n",
    "    c_list = []\n",
    "    post = reddit.submission(url = posts['url'][0])\n",
    "    post.comments.replace_more(limit=0)\n",
    "\n",
    "    for comment in post.comments.list():\n",
    "        this_list =  list([comment.author, \n",
    "        comment.body,\n",
    "        comment.created_utc,\n",
    "        comment.depth,\n",
    "        comment.downs,\n",
    "        comment.edited,\n",
    "        comment.gilded,\n",
    "        comment.is_submitter,\n",
    "        comment.likes,\n",
    "        comment.link_id,\n",
    "        comment.parent_id,\n",
    "        comment.id,\n",
    "        comment.locked,\n",
    "        comment.controversiality,\n",
    "        comment.mod_note,\n",
    "        comment.mod_reason_by,\n",
    "        comment.mod_reason_title,\n",
    "        comment.mod_reports,\n",
    "        comment.no_follow,\n",
    "        comment.permalink,\n",
    "        comment.removal_reason,\n",
    "        comment.report_reasons,\n",
    "        comment.score,\n",
    "        comment.stickied,\n",
    "        comment.total_awards_received, \n",
    "        comment.ups,\n",
    "        comment.subreddit,\n",
    "        comment.subreddit_id,\n",
    "        comment._submission])\n",
    "\n",
    "        c_list.append(this_list)\n",
    "\n",
    "\n",
    "    commentDF = pd.DataFrame(c_list,columns=['author', \n",
    "    'body', \n",
    "    'created_utc',\n",
    "    'depth',\n",
    "    'downs',\n",
    "    'edited',\n",
    "    'gilded',\n",
    "    'is_submitter',\n",
    "    'likes',\n",
    "    'link_id',\n",
    "    'parent_id',\n",
    "    'id',\n",
    "    'locked',\n",
    "    'controversiality',\n",
    "    'mod_note',\n",
    "    'mod_reason_by',\n",
    "    'mod_reason_title',\n",
    "    'mod_reports',\n",
    "    'no_follow',\n",
    "    'permalink',\n",
    "    'removal_reason',\n",
    "    'report_reasoned',\n",
    "    'score',\n",
    "    'stickied',\n",
    "    'total_awards_received',\n",
    "    'ups',\n",
    "    'subreddit',\n",
    "    'subreddit_id',\n",
    "    'submission_id'])\n",
    "\n",
    "    commentDF['created_utc'] = pd.to_datetime(commentDF['created_utc'] , format=None,unit='s',origin='unix')\n",
    "    print(f'~Done!!! {commentDF.shape[0]} comments found')\n",
    "    \n",
    "    return commentDF\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "~Getting posts for nba with limit 10\n~Done!!! 10 posts found in nba\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       id                                              title  \\\n0  g3h9mj            The Last Dance - Episode Discussion Hub   \n1  g540x8  [Game Thread] Portland Trailblazers (22-7) @ O...   \n2  g4sqx0  Jordan during his HOF speech: \"Jerry Krause is...   \n3  g51138  [Bleacher Report] RJ Barrett has made $250K wo...   \n4  g50yyg  [Ourand] \"The Last Dance\" numbers blew away ev...   \n\n          created_utc  score subreddit  \\\n0 2020-04-20 00:00:10    333       nba   \n1 2020-04-20 23:36:20     22       nba   \n2 2020-04-20 13:26:51  12088       nba   \n3 2020-04-20 20:52:44   1747       nba   \n4 2020-04-20 20:49:50    952       nba   \n\n                                                 url  num_comments  \\\n0  https://www.reddit.com/r/nba/comments/g3h9mj/t...             3   \n1  https://www.reddit.com/r/nba/comments/g540x8/g...            15   \n2                      https://streamable.com/rzpdvf          1114   \n3  https://twitter.com/br_nba/status/125232600111...            94   \n4  https://www.reddit.com/r/nba/comments/g50yyg/o...           182   \n\n                                            selftext  stickied  spoiler  ...  \\\n0  This thread contains links to all of the episo...      True    False  ...   \n1  >Take a look back at an instant classic from 2...      True    False  ...   \n2                                                        False    False  ...   \n3                                                        False    False  ...   \n4  From John Ourand of Sports Business Journal:\\n...     False    False  ...   \n\n                                               media  \\\n0                                               None   \n1                                               None   \n2  {'oembed': {'provider_url': 'https://streamabl...   \n3  {'oembed': {'provider_url': 'https://twitter.c...   \n4                                               None   \n\n                                         media_embed media_only is_video  \\\n0                                                 {}      False    False   \n1                                                 {}      False    False   \n2  {'content': '<iframe class=\"embedly-embed\" src...      False    False   \n3  {'content': '<blockquote class=\"twitter-video\"...      False    False   \n4                                                 {}      False    False   \n\n   is_original_content  gilded       edited  category banned_at_utc  archived  \n0                False       0  1.58736e+09      None           NaT     False  \n1                False       0        False      None           NaT     False  \n2                False       0        False      None           NaT     False  \n3                False       0        False      None           NaT     False  \n4                False       0  1.58742e+09      None           NaT     False  \n\n[5 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>created_utc</th>\n      <th>score</th>\n      <th>subreddit</th>\n      <th>url</th>\n      <th>num_comments</th>\n      <th>selftext</th>\n      <th>stickied</th>\n      <th>spoiler</th>\n      <th>...</th>\n      <th>media</th>\n      <th>media_embed</th>\n      <th>media_only</th>\n      <th>is_video</th>\n      <th>is_original_content</th>\n      <th>gilded</th>\n      <th>edited</th>\n      <th>category</th>\n      <th>banned_at_utc</th>\n      <th>archived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>g3h9mj</td>\n      <td>The Last Dance - Episode Discussion Hub</td>\n      <td>2020-04-20 00:00:10</td>\n      <td>333</td>\n      <td>nba</td>\n      <td>https://www.reddit.com/r/nba/comments/g3h9mj/t...</td>\n      <td>3</td>\n      <td>This thread contains links to all of the episo...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>{}</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>1.58736e+09</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>g540x8</td>\n      <td>[Game Thread] Portland Trailblazers (22-7) @ O...</td>\n      <td>2020-04-20 23:36:20</td>\n      <td>22</td>\n      <td>nba</td>\n      <td>https://www.reddit.com/r/nba/comments/g540x8/g...</td>\n      <td>15</td>\n      <td>&gt;Take a look back at an instant classic from 2...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>{}</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>g4sqx0</td>\n      <td>Jordan during his HOF speech: \"Jerry Krause is...</td>\n      <td>2020-04-20 13:26:51</td>\n      <td>12088</td>\n      <td>nba</td>\n      <td>https://streamable.com/rzpdvf</td>\n      <td>1114</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>{'oembed': {'provider_url': 'https://streamabl...</td>\n      <td>{'content': '&lt;iframe class=\"embedly-embed\" src...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>g51138</td>\n      <td>[Bleacher Report] RJ Barrett has made $250K wo...</td>\n      <td>2020-04-20 20:52:44</td>\n      <td>1747</td>\n      <td>nba</td>\n      <td>https://twitter.com/br_nba/status/125232600111...</td>\n      <td>94</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>{'oembed': {'provider_url': 'https://twitter.c...</td>\n      <td>{'content': '&lt;blockquote class=\"twitter-video\"...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>False</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>g50yyg</td>\n      <td>[Ourand] \"The Last Dance\" numbers blew away ev...</td>\n      <td>2020-04-20 20:49:50</td>\n      <td>952</td>\n      <td>nba</td>\n      <td>https://www.reddit.com/r/nba/comments/g50yyg/o...</td>\n      <td>182</td>\n      <td>From John Ourand of Sports Business Journal:\\n...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>None</td>\n      <td>{}</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>0</td>\n      <td>1.58742e+09</td>\n      <td>None</td>\n      <td>NaT</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "postDF = get_posts('nba')\n",
    "postDF.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x116297410>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='veqtor'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': 'cd34ef9a-6abd-11ea-a7ea-0ec6041e93a9',\n 'author_flair_text': 'ML Engineer',\n 'author_flair_text_color': 'dark',\n 'author_flair_type': 'text',\n 'author_fullname': 't2_8j14e',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'I am one of those script Kiddies in a way, I imported Keras (and '\n         'TensorFlow probability) into a Kaggle kernel and showed that the '\n         'number of confirmed cases would continue escalating, why?\\n'\n         '\\n'\n         'Well, a few weeks ago I wanted to show people, based on replication '\n         \"patterns seen in Italy and China, that this won't magically go away \"\n         'without social distancing and other active measures. This applies to '\n         \"Sweden, where I'm from, we're taking the least amount of measures to \"\n         'reduce the spread in Europe and we are at the bottom of amount of '\n         'intensive care units in Europe.\\n'\n         '\\n'\n         \"ML can be used to predict things, if done cleverly, but it's just a \"\n         'rough estimate, people need to be aware of that.\\n'\n         '\\n'\n         '&#x200B;\\n'\n         '\\n'\n         \"Futhermore, I'm now trying to apply GCNN's, Scibert, Transformers \"\n         'and NER to CORD-19 to help summarize the flood of papers coming out '\n         'on COVID-19... Useless? Maybe... But if I can help save one life by '\n         \"helping a doctor or researcher find the information they're looking \"\n         \"for then I don't feel my time is wasted.\",\n 'body_html': '<div class=\"md\"><p>I am one of those script Kiddies in a way, I '\n              'imported Keras (and TensorFlow probability) into a Kaggle '\n              'kernel and showed that the number of confirmed cases would '\n              'continue escalating, why?</p>\\n'\n              '\\n'\n              '<p>Well, a few weeks ago I wanted to show people, based on '\n              'replication patterns seen in Italy and China, that this '\n              'won&#39;t magically go away without social distancing and other '\n              'active measures. This applies to Sweden, where I&#39;m from, '\n              'we&#39;re taking the least amount of measures to reduce the '\n              'spread in Europe and we are at the bottom of amount of '\n              'intensive care units in Europe.</p>\\n'\n              '\\n'\n              '<p>ML can be used to predict things, if done cleverly, but '\n              'it&#39;s just a rough estimate, people need to be aware of '\n              'that.</p>\\n'\n              '\\n'\n              '<p>&#x200B;</p>\\n'\n              '\\n'\n              '<p>Futhermore, I&#39;m now trying to apply GCNN&#39;s, Scibert, '\n              'Transformers and NER to CORD-19 to help summarize the flood of '\n              'papers coming out on COVID-19... Useless? Maybe... But if I can '\n              'help save one life by helping a doctor or researcher find the '\n              'information they&#39;re looking for then I don&#39;t feel my '\n              'time is wasted.</p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1584918540.0,\n 'created_utc': 1584889740.0,\n 'depth': 2,\n 'distinguished': None,\n 'downs': 0,\n 'edited': False,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'fl700mj',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_fl700mj',\n 'no_follow': False,\n 'num_reports': None,\n 'parent_id': 't1_fkvx8x4',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/fl700mj/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': 6,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': 6,\n 'user_reports': []}\n{'_fetched': True,\n '_reddit': <praw.reddit.Reddit object at 0x10e48a7d0>,\n '_replies': <praw.models.comment_forest.CommentForest object at 0x116297450>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='thunder_jaxx'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': None,\n 'author_flair_text': None,\n 'author_flair_text_color': None,\n 'author_flair_type': 'text',\n 'author_fullname': 't2_pw9im3k',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'I agree that there is not much ML can do for now that can help to '\n         \"fight Covid. But don't you think that there can be small utility \"\n         'opensource software built that can help people take the right '\n         'measures and actions during this Covid outbreak?',\n 'body_html': '<div class=\"md\"><p>I agree that there is not much ML can do for '\n              'now that can help to fight Covid. But don&#39;t you think that '\n              'there can be small utility opensource software built that can '\n              'help people take the right measures and actions during this '\n              'Covid outbreak?</p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1584610138.0,\n 'created_utc': 1584581338.0,\n 'depth': 2,\n 'distinguished': None,\n 'downs': 0,\n 'edited': False,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'fkw1ibf',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_fkw1ibf',\n 'no_follow': True,\n 'num_reports': None,\n 'parent_id': 't1_fkvx8x4',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/fkw1ibf/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': 3,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': 3,\n 'user_reports': []}\n{'_fetched': True,\n '_reddit': <praw.reddit.Reddit object at 0x10e48a7d0>,\n '_replies': <praw.models.comment_forest.CommentForest object at 0x1162974d0>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='Blockw'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': None,\n 'author_flair_text': None,\n 'author_flair_text_color': None,\n 'author_flair_type': 'text',\n 'author_fullname': 't2_5gmgkkji',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'Did you not read the above comment?',\n 'body_html': '<div class=\"md\"><p>Did you not read the above comment?</p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1586346547.0,\n 'created_utc': 1586317747.0,\n 'depth': 3,\n 'distinguished': None,\n 'downs': 0,\n 'edited': False,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'fmradr1',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_fmradr1',\n 'no_follow': True,\n 'num_reports': None,\n 'parent_id': 't1_fl700mj',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/fmradr1/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': 0,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': 0,\n 'user_reports': []}\n{'_fetched': True,\n '_reddit': <praw.reddit.Reddit object at 0x10e48a7d0>,\n '_replies': <praw.models.comment_forest.CommentForest object at 0x116297550>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='ReginaldIII'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': None,\n 'author_flair_text': None,\n 'author_flair_text_color': None,\n 'author_flair_type': 'text',\n 'author_fullname': 't2_6h2lc',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'Stay put. Wash your hands. Assume you have it (regardless of if you '\n         \"do or don't) and your goal is now entirely minimizing your ability \"\n         'to spread it to others. \\n'\n         '\\n'\n         \"Even if you aren't interacting with vulnerable people, are the \"\n         'people you are interacting with then going and being near vulnerable '\n         'people.\\n'\n         '\\n'\n         \"You don't need an app for that. You just need to be cautious and \"\n         'patient. You need to open a reasonable line of dialog with your '\n         'peers and colleagues and be open and reasonable. You need to think '\n         'about the other first, and assume that others are therefore thinking '\n         'of you. \\n'\n         '\\n'\n         \"For those who feel that others can't be trusted to think about you, \"\n         'so you have to think about yourself. Okay, be selfish. Now what? Oh. '\n         \"You're still in exactly the same situation because ultimately the \"\n         'only thing you can actually do is limit personal exposure. \\n'\n         '\\n'\n         'Since my university cancelled all face to face activities our '\n         'students have been acting like fools. Travelling home to see their '\n         'parents, flying international on cheap flights. The purpose of us '\n         'closing campus was that everyone stayed put, binged netflix, watched '\n         'their streamed lectures, and generally did less damage than they '\n         'would if we kept campus open and they were all mingling in lecture '\n         'halls of 300+.\\n'\n         '\\n'\n         \"You don't need an app for this shit, you don't need fucking computer \"\n         'scientists of all people to deal with this shit. You need to wash '\n         'your hands and stay put. It really is that simple.',\n 'body_html': '<div class=\"md\"><p>Stay put. Wash your hands. Assume you have '\n              'it (regardless of if you do or don&#39;t) and your goal is now '\n              'entirely minimizing your ability to spread it to others. </p>\\n'\n              '\\n'\n              '<p>Even if you aren&#39;t interacting with vulnerable people, '\n              'are the people you are interacting with then going and being '\n              'near vulnerable people.</p>\\n'\n              '\\n'\n              '<p>You don&#39;t need an app for that. You just need to be '\n              'cautious and patient. You need to open a reasonable line of '\n              'dialog with your peers and colleagues and be open and '\n              'reasonable. You need to think about the other first, and assume '\n              'that others are therefore thinking of you. </p>\\n'\n              '\\n'\n              '<p>For those who feel that others can&#39;t be trusted to think '\n              'about you, so you have to think about yourself. Okay, be '\n              'selfish. Now what? Oh. You&#39;re still in exactly the same '\n              'situation because ultimately the only thing you can actually do '\n              'is limit personal exposure. </p>\\n'\n              '\\n'\n              '<p>Since my university cancelled all face to face activities '\n              'our students have been acting like fools. Travelling home to '\n              'see their parents, flying international on cheap flights. The '\n              'purpose of us closing campus was that everyone stayed put, '\n              'binged netflix, watched their streamed lectures, and generally '\n              'did less damage than they would if we kept campus open and they '\n              'were all mingling in lecture halls of 300+.</p>\\n'\n              '\\n'\n              '<p>You don&#39;t need an app for this shit, you don&#39;t need '\n              'fucking computer scientists of all people to deal with this '\n              'shit. You need to wash your hands and stay put. It really is '\n              'that simple.</p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1584610675.0,\n 'created_utc': 1584581875.0,\n 'depth': 3,\n 'distinguished': None,\n 'downs': 0,\n 'edited': False,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'fkw2cbl',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_fkw2cbl',\n 'no_follow': False,\n 'num_reports': None,\n 'parent_id': 't1_fkw1ibf',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/fkw2cbl/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': 9,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': 9,\n 'user_reports': []}\n{'_fetched': True,\n '_reddit': <praw.reddit.Reddit object at 0x10e48a7d0>,\n '_replies': <praw.models.comment_forest.CommentForest object at 0x116297590>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='flamingspew'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': None,\n 'author_flair_text': None,\n 'author_flair_text_color': None,\n 'author_flair_type': 'text',\n 'author_fullname': 't2_7hcfm',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'There’s a video analysis algo that can detect lies using video '\n         'footage of subdermal bloodflow. I’m wondering if it could be '\n         'repurposed to detect cardiovascular abnormalities caused by the '\n         'infection by training it against positive cases. '\n         'https://youtu.be/6diqpGKOvic?t=9m7s',\n 'body_html': '<div class=\"md\"><p>There’s a video analysis algo that can '\n              'detect lies using video footage of subdermal bloodflow. I’m '\n              'wondering if it could be repurposed to detect cardiovascular '\n              'abnormalities caused by the infection by training it against '\n              'positive cases. <a '\n              'href=\"https://youtu.be/6diqpGKOvic?t=9m7s\">https://youtu.be/6diqpGKOvic?t=9m7s</a></p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1584836885.0,\n 'created_utc': 1584808085.0,\n 'depth': 3,\n 'distinguished': None,\n 'downs': 0,\n 'edited': False,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'fl489p3',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_fl489p3',\n 'no_follow': True,\n 'num_reports': None,\n 'parent_id': 't1_fkw1ibf',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/fl489p3/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': 0,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': 0,\n 'user_reports': []}\n{'_fetched': True,\n '_reddit': <praw.reddit.Reddit object at 0x10e48a7d0>,\n '_replies': <praw.models.comment_forest.CommentForest object at 0x116297610>,\n '_submission': Submission(id='fks234'),\n 'all_awardings': [],\n 'approved_at_utc': None,\n 'approved_by': None,\n 'archived': False,\n 'associated_award': None,\n 'author': Redditor(name='botechga'),\n 'author_flair_background_color': None,\n 'author_flair_css_class': None,\n 'author_flair_richtext': [],\n 'author_flair_template_id': None,\n 'author_flair_text': None,\n 'author_flair_text_color': None,\n 'author_flair_type': 'text',\n 'author_fullname': 't2_60uiukr1',\n 'author_patreon_flair': False,\n 'author_premium': False,\n 'awarders': [],\n 'banned_at_utc': None,\n 'banned_by': None,\n 'body': 'Maybe machine learning would be more applicable to the economic side '\n         'of the outbreak.  \\n'\n         '\\n'\n         'Finding which sectors are hardest hit and what can be done to '\n         'improve other than monetary policy. \\n'\n         '\\n'\n         'There is already tons of data and proven methods.',\n 'body_html': '<div class=\"md\"><p>Maybe machine learning would be more '\n              'applicable to the economic side of the outbreak.  </p>\\n'\n              '\\n'\n              '<p>Finding which sectors are hardest hit and what can be done '\n              'to improve other than monetary policy. </p>\\n'\n              '\\n'\n              '<p>There is already tons of data and proven methods.</p>\\n'\n              '</div>',\n 'can_gild': True,\n 'can_mod_post': False,\n 'collapsed': False,\n 'collapsed_because_crowd_control': None,\n 'collapsed_reason': None,\n 'controversiality': 0,\n 'created': 1585443420.0,\n 'created_utc': 1585414620.0,\n 'depth': 4,\n 'distinguished': None,\n 'downs': 0,\n 'edited': 1585439441.0,\n 'gilded': 0,\n 'gildings': {},\n 'id': 'flr7lnv',\n 'is_submitter': False,\n 'likes': None,\n 'link_id': 't3_fks234',\n 'locked': False,\n 'mod_note': None,\n 'mod_reason_by': None,\n 'mod_reason_title': None,\n 'mod_reports': [],\n 'name': 't1_flr7lnv',\n 'no_follow': True,\n 'num_reports': None,\n 'parent_id': 't1_fkw2cbl',\n 'permalink': '/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/flr7lnv/',\n 'removal_reason': None,\n 'report_reasons': None,\n 'saved': False,\n 'score': -1,\n 'score_hidden': False,\n 'send_replies': True,\n 'stickied': False,\n 'subreddit': Subreddit(display_name='MachineLearning'),\n 'subreddit_id': 't5_2r3gv',\n 'subreddit_name_prefixed': 'r/MachineLearning',\n 'subreddit_type': 'public',\n 'total_awards_received': 0,\n 'treatment_tags': [],\n 'ups': -1,\n 'user_reports': []}\n"
    }
   ],
   "source": [
    "submission.comments.replace_more(limit=1)\n",
    "for comment in submission.comments.list():\n",
    "    # print(comment.body)\n",
    "    pprint.pprint(vars(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "~Getting comments for: https://www.reddit.com/r/MachineLearning/comments/fks234/nd_resources_and_channels_to_help_with_covid19/\n~Done!!! 52 comments found\n"
    }
   ],
   "source": [
    "test = get_comments(posts['url'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}